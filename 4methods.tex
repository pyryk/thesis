%!TEX root = thesis.tex

\chapter{Methods}
\label{chapter:methods}

In this chapter, I describe the methodological approach used for finding the answers to my research questions. I also argue about the reasons for selecting the methods, and reasons for excluding the other methods presented in section \ref{section:evaluatingreuse}. 

\emph{From a broad methodological perspective, this study follows the constructive approach. This means that a system is implemented and evaluated \citep{jarvinen_tutkimustyon_2012}. In more detail, I evaluated the implementation system through six case studies. In the evaluation stage, I employed both quantitative and qualitative data gathering and analysis methods.} The evaluation of process efficiency (RQ1) is measured quantitatively, examining the numeric characteristics of several case studies. The visualization effectiveness (RQ2) is evaluated qualitatively, analyzing whether the tool encourages the visualizer to conform to visualization guidelines.

Next, I will describe the methodological setting in more detail.

\section{Constructive Study}

\emph{In order to find answers to the research questions\footnote{How does a reusable software system affect the \emph{efficiency} of building geographical visualizations?}\footnote{How does a reusable software system affect the \emph{effectiveness} of geographical visualizations?}, I decided to conduct a constructive study by implementing and evaluating a reusable geovisualization tool.} Constructive research excels at finding answers to questions of type ``how useful is system X'' \citep{jarvinen_tutkimustyon_2012}, making it the most suitable research type for this thesis.

In practice, conducting a constructive study involves designing an artifact and evaluating its effect \citep{jarvinen_tutkimustyon_2012}. \emph{In this study, I built a reusable geographical visualization tool}, evaluating its effect on the effectiveness of the visualization and the efficiency of building the visualization. This can be done by performing a \emph{case study}, i.e., observing one or more visualization cases and evaluating the relevant properties in those cases. In this study, I selected six visualization cases to evaluate the effect of the implemented tool on effectiveness and efficiency of visualization. The cases were: 1) store map depicting the locations of Alko stores, 2) map of earthquakes in California after January 1, 1900, 3) regional voter turnout in the Finnish presidential election of 2012, 4) regional share of people with no secondary education in Finland, 5) travel times to a single destination in Helsinki metropolitan area, and 6) average travel times to multiple destinations in Helsinki metropolitan area. To enable as realistic evaluation as possible, all cases presented use real-life data in formats obtainable from the Web.

\section{Evaluating Software Reuse Effectiveness}

In section \ref{section:successfullreusefactors}, I concluded that it is critical to analyze and measure software reuse. In this study, I utilized both high-level and low-level analysis methods. High-level methods emphasize the development process and higher-level properties of software, while low-level methods are more concerned with the methods for measuring individual software projects. In addition, I select the metrics for measuring software code properties needed by the higher-level methods.

\subsection{High-level Evaluation}
As presented in section \ref{section:evaluatingreuse}, several methods for high-level software reuse analysis exist. \emph{In this study, I used the cost-benefit analysis method}. Cost-benefit analysis models consider both development costs for the reusable component and the reuse productivity and quality benefits. Unlike the other methods presented, such as the maturity assessment model, it is suitable for assessing a single piece of software instead of a complete software reuse program or a reusable software library.

\subsection{Low-level Evaluation}

The models presented above are high-level analysis tools which do not take a stance on how to measure the detailed data required by the measurements. Hence, the models need to be complemented with lower-level, more detail-oriented methods. \emph{Of the methods presented by \citet{mohagheghi_quality_2007}, I decided to use the case study method.} As the scope of this work does not allow for large sample sizes required by controlled experiment method, it is not a feasible alternative for this study. Moreover, using experience reports requires a considerable experience on creating and using reusable software which is not possible to achieve for this work.

\emph{I conducted the case studies through the sister project comparison method}, as according to \citet{mohagheghi_quality_2007}, it is suitable for evaluating a specific piece of reusable software. For the evaluation, I built several visualizations with and without the reusable tool, evaluating the difference in approaches.

\subsection{Software Code Metrics}

As described in section \ref{section:evaluatingreuse}, software code properties can be measured with several different metrics. In order to achieve as reliable evaluation as possible, I decided to use a diverse set of different software code metrics. As suggested by \citet{fenton_software_1998}, I evaluated the implementations by measuring the number of both physical and effective lines of code.

According to \citet{fenton_software_1998}, software code line counts should be complemented with metrics related to functionality and complexity of the software. \emph{Therefore, I decided to use the cyclomatic complexity measure of \citet{mccabe_complexity_1976} for determining the application complexity.} The method is superior to other methods presented mainly because it provides a computable measure with which it is possible to measure implementation details of a program. As discussed in chapter \ref{section:evaluatingreuse}, the ``problem complexity'' approach of \citet{fenton_software_1998} is not appropriate for evaluating different implementations of the same problem and thus it was not selected.

\emph{In addition to the metrics presented above, I decided to employ the \citeauthor{halstead_elements_1977} metrics for difficulty and effort.} The main advantage of these methods when compared to the previous methods is that they provide an explicit, direct measure for the properties. Like the metric of \citeauthor{mccabe_complexity_1976}, \citeauthor{halstead_elements_1977} metrics are computable from the program source code, making them effective for this study.

The COCOMO approaches of \citet{boehm_software_1981} were not used because they are either too vague (Basic COCOMO 81) or too process-centric (Intermediate and Detailed COCOMO 81, COCOMO II) for this study.

\section{Evaluating the Effectiveness of a Visualization}

I decided to examine whether the reusable visualization tool is advantageous to the effeciveness of the visualization, i.e., if visualizations built with the tool are likely to be more effective in conveying the information than visualizations built without the tool. To some degree, this can be done with several different methods. \emph{In this study, I decided to use visualization heuristics by \citet{zuk_heuristics_2006} and thematic mapping objectives by \citet{schlichtmann_visualization_2002} due to the fact that those are the most concrete guidelines presented.}

In addition to the methods selected, several other methods exist. While some of the methods are more concrete than others, it is notable that none of the methods provides formal, computable means for evaluation. According to \citet{kraak_cartographic_1998}, \emph{evaluating geographical visualizations is predominantly done by estimating the visualization subjectively in relation to its context}. This makes objective effectiveness evaluation complicated.

The principles by \citet{tufte_visual_1986}, such as data-ink ratio presented in section \ref{section:visualizationprinciples} can be used to evaluate the visualization. Another method for evaluation is presented by \citet{azzam_j-b_2013}. However, the correctness of these methods is disputed \citep{kosslyn_graphics_1985,inbar_minimalism_2007}. Moreover, the methods are too abstract for effective formal evaluation.

Visualization heuristics by \citet{zuk_heuristics_2006} presented in section \ref{section:visualizationprinciples} are significantly more concrete than the methods presented in the previous paragraph and can be used for efficiently analyzing a visualization. \emph{Therefore, I decided to use the heuristics for evaluating the tool's effect on visualization effectiveness.}

Geovisualization-specific evaluation methods consist of the methods of \citet{kraak_cartographic_1998} and \citet{schlichtmann_visualization_2002}. While the former is useful for designing a visualization, it is too abstract for assessing visualizations effectively. The latter consists of a number of mapping objectives presented in section \ref{subsection:effectivemaps}. When compared to the former, it is considerably more concrete, enabling more effective formal evaluation. \emph{Therefore, I decided to complement the heuristics presented in the previous paragraph with the mapping objectives by \citet{schlichtmann_visualization_2002}}.

Due to the fact that the sister project method selected for efficiency evaluation aims to produce as similar results as possible, I deemed it unpractical to use the sister projects for evaluating the visualization effectiveness. \emph{Therefore, I decided to evaluate the tool qualitatively by examining whether it benefits the visualizer in terms of conforming to the heuristics and achieving the objectives.} This conforms to the statement of \citet{kraak_cartographic_1998} related to subjective evaluation of geovisualization.
