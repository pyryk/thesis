%!TEX root = thesis.tex

% Also known as ``literature review''/``Kirjallisuuskatsaus''. About 20 pages long.

In order to build an efficient framework for visualizing geographical data, it is needed to study (a) how to visualize geodata and (b) how to build frameworks. We are going to tackle this problem by first studying the basics of data visualization with an emphasis on geographical data, maps and the visualization process. After visualization, we are going to study the essence of software reuse, focusing on building and evaluating reusable software, also known as software frameworks.

\chapter{Data Visualization}
\label{chapter:dataviz}

\section{Definition}

According to \citet[chap.~3]{kosara_visualization_2007}, there is no universally accepted definition of visualization. He proposes the following for a ``minimal set of requirements for any visualization'':

\begin{itemize}
	\item It is based on (non-visual) data
	\item It produces an image
	\item The results are readable and recognizable
\end{itemize}

According to him, while visualizations can also have other properties or qualities, such as interaction or visual efficiency, the requirements above are the ones needed for technical definition of the term. Moreover, it should be emphasized that according to this definition, visualization is the \emph{process} itself, not the result of it.

\citet[chap.~4]{kosara_visualization_2007} argues that visualization is separated into two types, \emph{pragmatic} and \emph{artistic} visualization. Pragmatic visualization focuses on the analysis of the data in order to show its relevant characteristics as efficiently as possible. Artistic visualization on the other hand concentrates on the communication of the concern behind the data, not the display of the actual data. \citeauthor{kosara_visualization_2007} states that while these types focus on the opposite sides of the visualization spectrum, it may be possible to close the gap using e.g. interaction.

The first requirement for visualizations by \citet{kosara_visualization_2007} dictates that the visualization is based on data. This is an essential characteristic of \emph{data} visualizations: the visualization is a function which takes data as an input and produces a visual object as an output. In less technical terms, this means that the visualization turns data into visual, effortlessly and efficiently digestible format.

This leads to the fact that the data and visualization are not inherently tied to each other; the visualization ``function'' can be independent of the data and thus it may be possible to create a visualization framework or platform which is able to function on a potentially wide range of data.

\fixme{The goal of visualization is (usually) better understanding of the data.}

% This may need to moved to Thematic Map Visualization part:
% ``As this thesis concentrates on the display of data, the analysis of data is considered mainly outside the scope.''

\section{Principles for Successful Data Visualization}

The requirements presented in the previous section are sufficient for the definition of data visualization. However, they do not convey any information about visualization quality. In order to discover the characteristics for successful data visualization, additional principles are needed. \citet[p.~13]{tufte_visual_1986} states that excellent graphics (i.e. results of visualizations) consist of ``complex ideas communicated with clarity, precision and efficiency''. In practice, this means that the graphics should emphasize the actual data and its nuances above everything else, while serving a clear purpose.

In addition to graphics principles presented in the previous paragraph, \citet[p.~93]{tufte_visual_1986} presents the concept of \emph{data-ink}. Data-ink represents the ink used for displaying the data in a visualization. He argues that in an excellent visualization, most, if not all, ink used should contribute to display of the data. However, research by \citet{inbar_minimalism_2007} suggests that maximizing the share of data-ink may not be beneficial to the user experience of the visualization. 

The principles presented above are essential, but too abstract in order to be used as a sole basis for defining a good visualization. However, when combined with the data visualization definition stated above, the principles become considerably more useful and concrete. \citet{azzam_j-b_2013} propose an adapted version of the definition by \citet{kosara_visualization_2007}, complementing the second requirement by requiring the produced image to represent the data truthfully. This definition effectively combines the definition by \citet{kosara_visualization_2007} with the principle of showing data introduced by \citet{tufte_visual_1986}. The adapted definition facilitates the process of creating a successful data visualizations by offering a more concrete version of Tufte's principles. It gives the developer of the visualization a concrete checklist for representing the data: make sure it does not (a) omit or (b) overrepresent any information \citep{azzam_j-b_2013}.

% \fixme{This section could really use some more content}

\fixme{If desperately in need of more background, add human perception in relation to information visualization (from Ware).}

\section{Visualizing Geographical Data}

\fixme{Visualization - Scientific Visualization - Map Visualization - \citet{kraak_cartographic_1998} has a good overview.}

The most natural way of visualizing geographical data is by using a map\citep[chap.~1]{kraak_cartographic_1998,kraak_cartography_2011}. This technique is called \emph{thematic mapping} \citep[chap.~1]{slocum_thematic_2014}. Thematic mapping does not require any specific format of data, except for the geographical dimension \citep[chap.~1]{kraak_cartography_2011}. However, the nature of the data has a great effect on the method, or type, of thematic mapping.

\subsection{Methods for Thematic Mapping}

As stated above, there are several types of geographical data, many of which are fundamentally different requiring different visualization methods. Therefore, several different thematic mapping methods have been developed. \citet[chap.~14-18]{slocum_thematic_2014} list some of the most typical ones: \fixme{rephrase the descriptions below}

\begin{itemize}
	\item Choropleth map - Shows data aggregated for a set of predefined areas (countries, regions etc)
	\item Isarithmic map - Maps with areas separated by contour lines.
	\item Dasymetric map - \fixme{what's this?}
	\item Proportional symbol map - like dot map, but replaces dots with relevant symbols of sizes proportional to the data
	\item Dot map - simple maps with dots on relevant locations
	\item Multivariate mapping - A map that shows data of several dimensions (in addition to location).
	\item Flow map - a map that shows ``flows'' from one area to another. Napoleon Russian campaign map.
\end{itemize}

When designing a software framework for geovisualization, it is not necessary to support every method above. However, as those are some of the most used ones, omitting any must be a conscious decision.

\fixme{describe the use cases for each type}

Even a single thematic map is often used for multiple different purposes \citep[chap.~2]{schlichtmann_visualization_2002}. For instance, a single map can be read on the \emph{overall level} (``where are the primary schools located in Helsinki metropolitan area?'') and \emph{elementary level} (``is there a primary school in Punavuori?''). Furthermore, some possible uses for a thematic map are ``what is the ratio and distribution of Finnish schools compared to Swedish schools in Helsinki'' or ``what is the spatial distribution of sizes of schools in Helsinki''. Therefore, an efficient map visualization should not lock the user to any single perspective. \fixme{maybe move somewhere? Create a separate (sub)section for interactivity?} \fixme{Interactivity could help here? See \citep{andrienko_interactive_1999}}

\fixme{Analysis part of geovisualization - ``...is considered out of the scope of this work.''}

~

\fixme{To Do}
\begin{itemize}
	\item Geographic visualization (e.g. in relation to scientific visualization)
	\item Map visualization vs. map (thematic map vs general-reference map) \citep{bartz_petchenik_place_1979}
	\item How do the principles introduced in the previous subsection apply to geographical data? Is there anything else to consider?
	\item Thematic map interactivity \citep{andrienko_interactive_1999} (Where should this go? Is this an env related thing or here somewhere)
\end{itemize}

\citet[p.~16]{tufte_visual_1986} May help here as well.

\section{How Thematic Maps Are Made}
\citet{schlichtmann_visualization_2002} describes making thematic maps as a six-step process. The first four steps involve deciding on and obtaining the data which are not relevant when building a software framework for visualization. Therefore, we ignore those steps. The step five consists of selecting the visualization method and using it to produce a meaningful visualization from the data. The step six involves explaining the visualization in legend. \fixme{Schlichtmann not concerned with the step 6, find some other source of displaying the legend.}

In the map visualization process, several identified objectives for the resulting graphic exist \citep{schlichtmann_visualization_2002}. The objectives are presented in the table below.

\LTcapwidth=\textwidth
\begin{longtable}{|p{3cm}|p{10cm}|}
\hline
\textbf{Name} & \textbf{Description} \\ 
\hline
Clarification & Making the map clear and readable. In practice, this means that the topemes (symbols) in a map should be easily detectable and distinguishable from each other \\
\hline
Emphasis & Making topemes and other important characteristics of the visualization to stand out visually \\
\hline
Types of Entries & Having a clearly distinguishable type for each topeme. \\
\hline
Sets of Types & Grouping data points and symbols with similar traits in order to make them belong together visually. Ideally, the visual similarity should be related to the conceptual similarity. \\
\hline
Cross-Relations & Visually indicating the potential relations and similarities between different types or between entries of different types. \\
\hline
Local Syntax & Aligning visual properties of the topemes to prevent unintentional emphasis of single topemes. \\
\hline
Local Ensembles & Supporting topemes with multiple properties (such as the numbers of children and adults in an area) so that the topeme visually reflect both the individual properties and the combination of all properties. \\
\hline
Multilocal Ensembles & Supporting topemes with multiple geographical properties (such as spatial distribution of people)  \\
\hline
Addable and Non-Addable Quantities & Differentiating addable and non-addable properties. Typically absolute quantitative properties are addable while relative and qualitative properties are non-addable. Addable properties should be visualized in a way that cognitively supports addition (e.g. with sizes of elements) while non-addable quantities should be visualized without said feature (e.g. with colors.) \\
\hline
The Surface Illusion & Creating an illusion of surface on the map. This can be achieved for example by using illumination and shadowing. These visual traits can convey a meaning themselves and often naturally do so. \\
\hline
\caption{Map visualization objectives as per \citet{schlichtmann_visualization_2002}}
\end{longtable}

The objectives above are important when visualizing geographical data on a map. Therefore, it is needed to take those into account when creating a visualization tool or framework in order to enable or even encourage the visualizers to reach as many of the objectives as possible.

\fixme{This could use an opinion from some other source as well (Maybe \citep[p.~5]{slocum_thematic_2014})}

\chapter{Software Reuse}
\label{chapter:reuse}

In order to create a reusable software framework for visualization, it is necessary to study software reuse along with different reuse techniques and their characteristics, advantages and disadvantages.

\citet{krueger_software_1992} presents software reuse as a process of reusing existing software code (applications, libraries, functions or single lines) when building new software, while according to \citet{mohagheghi_empirical_2008}, reuse is not restricted to code, but can also refer to other software assets such as design. However, both agree that software reuse combines several different existing pieces of code (and possibly other assets) along with new assets which are specific for the application in question. According to \citet{mcilroy_mass-produced_1969} and \citet{boehm_managing_1999}, it is one of the most effective techniques of reducing the development time and cost of complex software products.

\section{Software Reuse Advantages \& Disadvantages}

When used appropriately, software reuse has several benefits. In their overview of multiple case studies, \citet{mohagheghi_empirical_2008} discovered that in most cases, using reused software components resulted in a considerably lower number of software defects and better productivity. Several of the studies implied that reusing software is also beneficial for software complexity and product time-to-market. However, it should be noted that since the overview only addresses case studies, its results should not be considered universally applicable.

Although reusing software is often said to decrease the effort needed \citep{mcilroy_mass-produced_1969, boehm_managing_1999, mohagheghi_empirical_2008} \fixme{there must be many more sources for this available}, concrete evidence for this is difficult to find \citep{mohagheghi_empirical_2008}.

Given its lucrative advantages, software reuse is definitely beneficial for many software systems. However, according to \citet{krueger_software_1992}, software reuse can be problematic and even disadvantageous. Learning to use a specific piece of reusable software often takes considerable effort. Moreover, finding suitable code fragments may also prove to be a challenge. For uncomplicated software systems and especially reusable components, it may not be worth the effort. Therefore, developer needs to carefully consider all sides of reusing when building a software system; according to \citet[chap.~1.3]{krueger_software_1992}, for successful software reuse scenario, the amount of intellectual effort between the concept and implementation of the system must be as low as possible. In practice, this means that the value of the reused component must be as high as possible for the developed system, while the implementation cost (resources needed to take the reusable component into use) should be relatively low. 

\section{Factors for Successful Software Reuse}
\citet{frakes_success_1994} state that for successful software reuse, the procedure must be planned beforehand and evaluated with a cost-benefit analysis. \fixme{They also present several other factors, add them here.} \fixme{This needs a lot more flesh. Add some general principles etc. ``How to make reusable software''}

\section{Analyzing Software Reuse}
According to \citet{krueger_software_1992}, in order to analyze reusing software, the reuse process to be studied should be separated into four \emph{dimensions}. The dimensions are presented below.

~

\textbf{Abstraction} is the process of making a piece of software more generic, thus making it applicable to a wider range of software projects. Software reuse is almost always based on abstraction, but according to \citet{krueger_software_1992}, raising the abstraction level has proven to be difficult, thus making building reusable software a nontrivial process.\newline

\textbf{Selection} facilitates finding, comparing and choosing suitable pieces of software. For example, libraries or frameworks aid selection by bundling and structuring the software components.\newline

\textbf{Specialization} is the process of making the abstracted component more specific, usually by parameterizing the software or making it transformable.\newline

\textbf{Integration} facilitates providing the software with reusable components, for example with a mechanism to import relevant modules or functions to the software.\newline

\fixme{Add advantages and disadvantages in general about reuse, not about different methods as those are described in the reuse methods chapter. Software reuse metrics research \citep{mohagheghi_empirical_2008,frakes_software_1996,selby_enabling_2005} probably has some good points. Also, \citet{johnson_frameworkscomponents+_1997} may have something.}

\section{Software Reuse Methods}

%Here should be analysis about libraries, components, frameworks... Use \citet{krueger_software_1992}. Also why choose framework? \citet{johnson_frameworkscomponents+_1997} has some reasons.

%\citet{krueger_software_1992} has a list of different methods along with their advantages and disadvantages. Includes frameworks in chapter 10. \citet{johnson_frameworkscomponents+_1997} extends the description. Using the characteristics along with praise of \citet{johnson_frameworkscomponents+_1997}, it should be possible to reason about going with frameworks.

~

Software reuse is not a single, uniform procedure or technique. Several different reuse techniques exist to cater different needs. Consequently, different reuse methods excel at different areas. In order to describe the advantages and disadvantages of the methods, we describe the using the reuse dimensions presented in the previous section.

\citet{krueger_software_1992} and \citet{johnson_frameworkscomponents+_1997}, among others, present and analyze software reuse methods. From these, we have selected the most relevant for web environment, presenting those below.

% High-level languages, design and code scavenging, source code components, software schemas, application generators, very high-level languages, transformational systems, software architectures

\subsection{High-Level Languages}
High-level languages denote programming languages which are designed to be on a high abstraction level and thus contain features which are not necessary for a programming language but benefit or speed up the development. Traditional examples of these kind of features are automatic memory allocation \citep{krueger_software_1992} and language constructs such as exceptions \citep{mitchell_concepts_2003}. More modern high-level language features are value type checking systems and abstracted support for parallel operations using futures \citep{totoo_haskell_2012}. It should be noted that the high-levelness of a language is a \emph{relative} property, i.e. it is not possible to determine the requirements for a high-level language per se, only high-levelness of languages compared to other languages. For example, \citet{krueger_software_1992} considers all programming languages above the abstraction level of the assembly language high-level languages, while \citet{carro_high-level_2006} consider e.g. lack of automatic memory management or type system a sign of lower-level language.

High-level languages \emph{abstract} frequently used procedures into seemingly uncomplicated operations, thus reducing the work and cognitive capacity needed for developing the application. \citep[chap.~3]{krueger_software_1992}

As the number of elementary high-level language constructs is usually relatively low it is possible for programmers to master the use of those constructs with sufficiently little effort, rendering \emph{selection} unproblematic. \citep[chap.~3]{krueger_software_1992}

\emph{Specialization} of high-level language features is usually achieved by parameterizing the constructs, either implicitly or explicitly. For example, when instantiating a class in Java, the only parameterization needed for memory management is the actual object instance. However, e.g. exception handling always requires at least the logic needed for handling the exception. \citep[chap.~3]{krueger_software_1992}

\emph{Integration} of high-level language features is automatically done when compiling the software code. However, due to the nature of high-level languages, it is usually not possible to mix-and-match different programming languages easily in the same program. \citep[chap.~3]{krueger_software_1992}

The advantages of high-level languages are mainly related to the decreased need for developing frequently needed procedures manually, such as allocating or deallocating memory, case-by-case. These operations in high-level languages can be mapped into more complex procedures in some lower-level languages, effectively making them reusable software components. In practice, using high-level languages can yield a productivity gain up to 500 \%. \citep[chap.~3]{krueger_software_1992}

The main disadvantage of using high-level languages is the potential decrease in performance. As with any software reuse, high-level programming languages abstract the supported procedures by making them more generic. This often leads to additional complexity and unnecessary operations on the compiled program. However, the decrease can often be minimized by using additional compile-time optimizations. \citep{carro_high-level_2006}

On the web, the technologies used on the client-side are inherently fixed to descendants of HTML, CSS and JavaScript \citep{world_wide_web_consortium_html5_2014,world_wide_web_consortium_cascading_2011,ecma_ecmascript_2011}. Therefore, web application languages are relatively high-level by definition. However, it is still possible to raise the abstraction level by using e.g. CoffeeScript \citep{ashkenas_coffeescript_2009} instead of JavaScript or LESS \citep{sellier_less_2009} instead of CSS.

\subsection{Design and Code Scavenging}

Design and Code scavenging refers to the technique of scavenging pieces of software \emph{ad hoc} from existing software systems and using the pieces as parts for a new software system  \citep[chap.~4]{krueger_software_1992}. The aim of this technique is to reduce the amount of work needed to build the system. For example, when building an UI component for choosing a date, the developer may scavenge the code for a calendar from an older software system.

Scavenging can be done without modifications to the code in the target code base (code scavenging) or by modifying the details of the scavenged code (design scavenging) \citep[chap.~4]{krueger_software_1992}. The \emph{abstraction} gained by scavenging is therefore mostly informal and in some cases even its existence is questionable \citep[chap.~3]{sametinger_software_1997}. Usually, there is no ``hidden part'' of the abstraction but the developer must maintain the functionality of all the code himself \citep[chap.~3]{sametinger_software_1997}.

Usually there is no formal mechanism or support for \emph{selecting} pieces of software to be scavenged. Therefore, the developer must rely on his memory, experience and word-of-mouth in order to find suitable pieces of software. \citep[chap.~3]{sametinger_software_1997}

\emph{Specialization} is done by manually editing the scavenged source code. While it is often the fastest method of acquiring results, this requires the developer to deeply understand the scavenged implementation. It can also lead to fragmentation and maintainability issues in the future. \citep[chap.~4]{krueger_software_1992}

\emph{Integration} of the scavenged code is done by copying and pasting the code to the target source code file. This may lead to namespace collisions between original and scavenged code which may result in the need for refactoring the code. \citep[chap.~4]{krueger_software_1992}

The main advantages of design and code scavenging are the ability to quickly include existing functionality to new software systems \citep[chap.~4]{krueger_software_1992}. As it is usually not needed to prepare the code to be scavenged before scavenging it, the extent of possible pieces of software is often significantly larger than when using any other reuse method. 

However, finding suitable pieces of software for scavenging is hard. Moreover, scavenging pieces of software often does not decrease the \emph{cognitive distance} between the target and implementation of the system. It may also create issues with maintainability of the software. \citep[chap.~4]{krueger_software_1992}

\subsection{Source Code Components}

Using source code components is a type of reuse that chooses and uses software components from a component repository \citep[chap.~3]{sametinger_software_1997}. Software component can be any piece of code, but in practice, components usually consist of one or more functions, modules or classes \citep[chap.~3]{sametinger_software_1997}. An example of a source code component is a trigonometry module which contains functions for sine, cosine and tangent calculations. When a developer needs to calculate sines in her program, she searches a component repository for trigonometry components and utilizes the component found in her own program \citep[chap.~5]{krueger_software_1992}.

Ideally, source code components \emph{abstract} the implementation details of the component inside. This means that the required cognitive distance between the concept and the implementation of the software system is lower when using source code components instead of e.g. code scavenging. 

In order to be \emph{selectable}, source code components should be accompanied by abstract names (function names) and descriptions of the functionality provided \citep[chap.~5]{krueger_software_1992}. The names should describe \emph{what} the components does instead of \emph{how} it does it \citep[chap.~5]{krueger_software_1992}. These names can then be used for reasoning about the purpose of the component and finding the component in source code component repositories -- in order to use the component, the developer must be able to find it and to know what it does \citep[chap.~5]{krueger_software_1992}.

Source code components can be \emph{specialized} by modifying the source code \citet[chap.~5]{krueger_software_1992}. However, as this technique yields unwanted consequences explained in the previous section, many components support specialization by parameterization. For example, the programmer could provide the sine function the angle in question. Additionally, when integrating the trigonometry module to her software system, the programmer could specify if the functions should use degrees or radians. In some components, specialization can also be achieved via subclassing \citep[chap.~5]{krueger_software_1992}.

All modern programming languages support \emph{integration} of reusable source code components written in the same language. Usually, the procedure is a very simple addition of source code files, which requires little to no effort on the programmer side. However, all source code components can't be used in the same program due to conflicts e.g. in naming and value types \citep[chap.~5]{krueger_software_1992}.

The main advantages of using source code components are the abstraction provided and organized nature of the component repositories. Ideally, the repositories provide a search functionality so that even developers with no previous experience on the component domain can find the components needed. Moreover, the abstraction level and the hiding of implementation details decreases the cognitive distance between the concept and the implementation of the system and reduce the source code needed to be written.

The main disadvantages of the source code components lie in the fact that the functionality must be deliberately designed to support reuse. The abstraction of the components is a major challenge \citep[chap.~5]{krueger_software_1992} in designing source code components. Additionally, the component repositories need administration and maintenance.

\subsection{Software Schemas}

\fixme{Add similarly structured content as in the previous subsubsection. Or maybe drop?}

\subsection{Application Generators}

Application generators are usually domain-specific generators which take very high level instructions (specifications) as input and then output significantly lower level software code (implementation) \citep[chap.~7]{cleaveland_building_1988,krueger_software_1992}. On fundamental level, application generators differ from high-level language compilers mainly by being designed to work on a narrow domain and thus being able to support considerably higher-level instructions \citep[chap.~7]{krueger_software_1992}. Unlike source code components, the reused components generated by application generators are usually not encapsulated or separated \citep[chap.~3]{sametinger_software_1997}.

Application generators \emph{abstract} the concept or specification of the software system, hiding the actual implementation completely from the user of the generator \citep{cleaveland_building_1988}. However, in some cases it may be necessary to modify the output of the generator which essentially removes the abstraction.

In principle, \emph{selecting} application generations is moderately easy since the abstraction level of application generators is usually very high, rendering reasoning about the purpose of the generator fairly easy \citep[chap.~7]{krueger_software_1992}. However, since application generators are usually suited for a very narrow domain, it is usually difficult to find a suitable generator \citep[chap.~7]{krueger_software_1992}.

Typically, software systems generated with application generators consist of variant and invariant parts \citep[chap.~7]{krueger_software_1992}. Invariant part is the part of the program which the developer using the generator can't modify. The developer \emph{specializes} the program by modifying the variant part. There are several methods of modifying the variant part. One of the simplest may be straightforward parameterization: the developer chooses the parameters of the system from a predefined set of alternatives. This method makes using the generation extraordinarily easy. However, it also limits the resulting application considerably.

On the other end of the spectrum, the application generator may require the variant parts to be inputted using a domain-specific or generic-purpose programming language. This makes the application generator incredibly versatile, but requires both more domain-specific and programming knowledge.

Typically, application generators generate complete applications which do not require further \emph{integration} \citep[chap.~7]{krueger_software_1992}. However, occasionally, the resulting applications are not independent per se, but require integration to other systems. This may be an issue since often it is not possible to select the integration interfaces freely, but to use the ones provided by the generator.

One of the main advantages of the application generators is the abstraction they provide. In some cases, the application generators may even require no programming language knowledge as long as the user has relevant domain-specific knowledge \citep{horowitz_survey_1985}. Moreover, application generators excel when there is a need for building multiple similar applications \citep[chap.~7]{krueger_software_1992}. 

However, application generators require an unambiguous mapping between the specifications and implementation details \citep[chap.~7]{krueger_software_1992}. Moreover, building application generators requires a reliable, generic implementation and user interfaces for developers \citep{cleaveland_building_1988}. Therefore, building application generators requires comprehensive domain-specific knowledge in addition to extensive software development expertise.

\subsection{Very High Level Languages}

\fixme{Or domain-specific languages? Add similarly structured content as in the previous subsubsection}

\subsection{Transformational Systems}

\fixme{Add similarly structured content as in the previous subsubsection. Or maybe drop?}

\subsection{Software Architectures}

\fixme{Add similarly structured content as in the previous subsubsection}

\subsection{Software Frameworks}

\fixme{Add similarly structured content as in the previous subsubsection. Are frameworks the same as architectures? If, drop.}

%\subsection{Software Frameworks}

%Frameworks more in depth. Maybe how to build them.

%\fixme{Is it OK to describe frameworks in depth, but not other means of reuse? How to reason about this? Could it be done so that frameworks do not have a separate chapter (here), but instead go through all methods. Then, in the implementation chapter, reason about which methods to use (most likely more than just framework here)}

\section{Evaluating Software Reuse Effectiveness}

Here should be the whole research on how to measure if it is beneficial to reuse software instead of writing from scratch. At least \citet{mohagheghi_empirical_2008,frakes_software_1996,selby_enabling_2005} are useful here.

\chapter{Research Gap}
\label{chapter:researchgap}

Currently, research on geographic or map visualization is abundant \fixme{Use a bunch of geoviz references to prove this? Or some other way?}. Moreover, according to the visualization definition by \citet{kosara_visualization_2007}, it may be possible to abstract parts of the visualization implementation in order to achieve visualization process which requires less effort and technical knowledge. However, both research about geovisualization-related software reuse and actual reusable geovisualization components are scant. This implies that there is room for improvement in both research and implementation related to geovisualization software. \fixme{IMHO this is way too short for a chapter. How to fix?}

\begin{itemize}
	\item Current research does not completely cover the field of this thesis
	\item There is research about visualizing geographic content (generally or on the web)
	\item According to literature, it is possible to abstract parts of the implementation of web geovisualization.
	\item However, there is little (or no) research on how to make geovisualization more efficiently
\end{itemize}
